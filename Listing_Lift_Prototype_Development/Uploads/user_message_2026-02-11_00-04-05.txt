This is exactly what we need. `flux-kontext` is ~4 seconds for image editing vs `gpt-image-1` which takes 100+ seconds. Here's the complete fix:

---

## Enhancement Debug V2 — Analysis & Fix

### What's Happening

Great news: **the API call is working correctly.** The logs confirm:
- ✅ API key is valid
- ✅ Model name `gpt-image-1` is accepted
- ✅ Prompt is being sent (2,681 chars)
- ❌ But `gpt-image-1` takes **100+ seconds** for image editing, and Cloudflare's proxy kills the connection at ~100s → 524 timeout

### The Fix: Two Changes

**Primary fix:** Switch from `gpt-image-1` to `flux-kontext`. According to [benchmarks](https://simplismart.ai/blog/flux-1-kontext-dev-api), FLUX Kontext handles image-to-image edits in **~4-12 seconds** vs GPT-Image-1's 100+ seconds. It's specifically designed for instruction-based image editing (exactly your use case). It's [available on Abacus AI RouteLLM](https://abacus.ai/help/developer-platform/route-llm/api) as a supported image generation model.

**Secondary fix:** Re-upload the enhanced image to your own S3 bucket. This solves the CORS issue — the URL returned by Abacus AI is on their S3 bucket which doesn't have CORS headers for your `listinglift.abacusai.app` domain. By downloading the image server-side and re-uploading to your own bucket, you control the CORS and the image is permanently stored.

---

### Complete Code for DeepAgent

**Replace the entire file** `/app/api/photos/[id]/enhance/route.ts` with:

```typescript
import { NextResponse } from "next/server";
import { prisma } from "@/lib/db";
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth-options";
import { ROOM_PROMPTS, INTENSITY_MODIFIERS } from "@/lib/enhancement-prompts";
import { getFileUrl, uploadBufferToS3 } from "@/lib/s3";

export const dynamic = "force-dynamic";
export const maxDuration = 60; // flux-kontext should complete in <15 seconds

export async function POST(
  request: Request,
  { params }: { params: { id: string } }
) {
  const session = await getServerSession(authOptions);
  if (!session) {
    return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
  }

  try {
    const data = await request.json();
    const {
      intensity = "Moderate",
      skyReplacement = false,
      bedFixing = false,
      windowRecovery = false,
      brightness = false,
      perspective = false,
      reflection = false,
      additionalNotes = "",
      customPrompt = ""
    } = data;

    // Get photo with original URL
    const photo = await prisma.photo.findUnique({
      where: { id: params.id },
      include: {
        enhancementVersions: {
          orderBy: { versionNumber: 'desc' },
          take: 1
        }
      }
    });

    if (!photo) {
      return NextResponse.json({ error: "Photo not found" }, { status: 404 });
    }

    // Get accessible URL for the original photo
    const originalUrl = await getFileUrl(photo.originalUrl, true);

    // Build the prompt
    let prompt: string;
    if (customPrompt && customPrompt.trim()) {
      prompt = customPrompt.trim();
    } else {
      const roomKey = photo.subCategory || photo.roomCategory;
      prompt = ROOM_PROMPTS[roomKey] || ROOM_PROMPTS[photo.roomCategory] || ROOM_PROMPTS["Kitchen"];
      prompt += INTENSITY_MODIFIERS[intensity] || INTENSITY_MODIFIERS["Moderate"];
    }

    // Add enhancement toggles
    const toggles: string[] = [];
    if (skyReplacement) toggles.push("Apply sky replacement with pleasant blue sky");
    if (bedFixing) toggles.push("Smooth and fix bed linens to appear crisp and inviting");
    if (windowRecovery) toggles.push("Recover and reveal exterior view through windows");
    if (brightness) toggles.push("Increase overall brightness and reduce shadows");
    if (perspective) toggles.push("Correct perspective and straighten vertical lines");
    if (reflection) toggles.push("Remove photographer reflections from mirrors and glass");

    if (toggles.length > 0) {
      prompt += `\n\nADDITIONAL ENHANCEMENT INSTRUCTIONS:\n${toggles.join('\n')}`;
    }

    if (additionalNotes) {
      prompt += `\n\nADMIN NOTES:\n${additionalNotes}`;
    }

    console.log('[ENHANCE] Starting enhancement for photo:', params.id);
    console.log('[ENHANCE] Using model: flux-kontext');
    console.log('[ENHANCE] Original URL:', originalUrl?.substring(0, 100) + '...');
    console.log('[ENHANCE] Prompt length:', prompt.length);

    // Call Abacus AI RouteLLM API with flux-kontext (fast image editing, ~4-12 seconds)
    const response = await fetch('https://apps.abacus.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.ABACUSAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'flux-kontext',
        messages: [
          {
            role: 'user',
            content: [
              { type: 'image_url', image_url: { url: originalUrl } },
              { type: 'text', text: prompt }
            ]
          }
        ],
        modalities: ['image'],
        image_config: {
          num_images: 1,
          aspect_ratio: photo.orientation === 'portrait' ? '3:4' : '4:3'
        },
        max_tokens: 1000
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('[ENHANCE] API error:', response.status, errorText);
      return NextResponse.json({
        error: "Enhancement API failed",
        details: errorText.substring(0, 500),
        status: response.status
      }, { status: 500 });
    }

    const result = await response.json();
    console.log('[ENHANCE] API response received');
    console.log('[ENHANCE] Response keys:', JSON.stringify(Object.keys(result)));

    // Extract image URL from response — check multiple possible locations
    let enhancedImageUrl = '';

    // Location 1: message.content array with type "image_url"
    const content = result.choices?.[0]?.message?.content;
    if (Array.isArray(content)) {
      for (const item of content) {
        if (item?.type === 'image_url' && item?.image_url?.url) {
          enhancedImageUrl = item.image_url.url;
          break;
        }
      }
    }

    // Location 2: message.images array
    if (!enhancedImageUrl) {
      const images = result.choices?.[0]?.message?.images;
      if (images && images.length > 0) {
        enhancedImageUrl = images[0]?.image_url?.url || images[0]?.url || '';
      }
    }

    // Location 3: direct URL in content string
    if (!enhancedImageUrl && typeof content === 'string' && content.startsWith('http')) {
      enhancedImageUrl = content;
    }

    console.log('[ENHANCE] Extracted image URL:', enhancedImageUrl ? enhancedImageUrl.substring(0, 100) + '...' : 'NONE');

    if (!enhancedImageUrl) {
      console.error('[ENHANCE] No image URL found in response:', JSON.stringify(result).substring(0, 1000));
      return NextResponse.json({
        error: "No enhanced image returned from API",
        debug: JSON.stringify(result).substring(0, 500)
      }, { status: 500 });
    }

    // Re-upload enhanced image to our own S3 to avoid CORS issues
    let finalImageUrl = enhancedImageUrl;
    try {
      console.log('[ENHANCE] Downloading enhanced image to re-upload to our S3...');
      const imageResponse = await fetch(enhancedImageUrl);
      if (imageResponse.ok) {
        const imageBuffer = Buffer.from(await imageResponse.arrayBuffer());
        const contentType = imageResponse.headers.get('content-type') || 'image/jpeg';
        const ext = contentType.includes('png') ? 'png' : 'jpg';
        const s3Path = await uploadBufferToS3(
          imageBuffer,
          `enhanced-${params.id}-${Date.now()}.${ext}`,
          contentType
        );
        finalImageUrl = await getFileUrl(s3Path, true);
        console.log('[ENHANCE] Re-uploaded to our S3:', s3Path);
      } else {
        console.warn('[ENHANCE] Could not download enhanced image for re-upload, using original URL');
      }
    } catch (reuploadError) {
      console.warn('[ENHANCE] Re-upload failed, using original URL:', reuploadError);
      // Fall back to the API-returned URL — may have CORS issues but at least it's saved
    }

    // Save to database
    const versionNumber = (photo?.enhancementVersions?.[0]?.versionNumber || 0) + 1;

    await prisma.enhancementVersion.create({
      data: {
        photoId: params.id,
        versionNumber,
        enhancedUrl: finalImageUrl,
        intensity,
        skyReplacement,
        bedFixing,
        windowRecovery,
        brightness,
        perspective,
        reflection,
        additionalNotes: additionalNotes || null
      }
    });

    await prisma.photo.update({
      where: { id: params.id },
      data: {
        enhancedUrl: finalImageUrl,
        status: 'Enhanced'
      }
    });

    console.log('[ENHANCE] Success! Version:', versionNumber);

    return NextResponse.json({
      status: 'completed',
      enhancedUrl: finalImageUrl,
      versionNumber
    });

  } catch (error) {
    console.error('[ENHANCE] Enhancement error:', error);
    return NextResponse.json({
      error: "Enhancement failed",
      details: error instanceof Error ? error.message : String(error)
    }, { status: 500 });
  }
}
```

---

### Add `uploadBufferToS3` helper function to `/lib/s3.ts`

Add this new function to the existing `s3.ts` file (at the end, before the last closing bracket or after the existing exports):

```typescript
export async function uploadBufferToS3(
  buffer: Buffer,
  fileName: string,
  contentType: string
): Promise<string> {
  const timestamp = Date.now();
  const sanitizedFileName = fileName.replace(/[^a-zA-Z0-9._-]/g, "_");
  const cloud_storage_path = `${folderPrefix}public/enhanced/${timestamp}-${sanitizedFileName}`;

  const command = new PutObjectCommand({
    Bucket: bucketName,
    Key: cloud_storage_path,
    Body: buffer,
    ContentType: contentType,
    ContentDisposition: "inline",
  });

  await s3Client.send(command);

  return cloud_storage_path;
}
```

This function takes a raw image buffer and uploads it directly to your S3 bucket under a `public/enhanced/` prefix. The enhanced images are now stored in your own bucket with the correct CORS configuration.

---

### Client-side `handleEnhance` — keep as-is from last prompt

The `handleEnhance` function from the previous prompt (the simplified JSON-based version, not SSE streaming) is still correct. If DeepAgent already applied it, no changes needed. If not, here it is again:

```typescript
const handleEnhance = async () => {
  if (!selectedPhoto) return;
  setEnhancing(true);

  try {
    const response = await fetch(`/api/photos/${selectedPhoto.id}/enhance`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(enhanceSettings)
    });

    const result = await response.json();

    if (!response.ok) {
      console.error('Enhancement failed:', result);
      alert(`Enhancement failed: ${result.error || 'Unknown error'}${result.details ? '\n\nDetails: ' + result.details : ''}`);
      return;
    }

    if (result.status === 'completed' && result.enhancedUrl) {
      await fetchSubmission();
      alert('Enhancement complete!');
    } else {
      console.error('Unexpected response:', result);
      alert('Enhancement returned unexpected response. Check console for details.');
    }
  } catch (error) {
    console.error('Enhancement failed:', error);
    alert('Enhancement failed. Please try again.');
  } finally {
    setEnhancing(false);
  }
};
```

---

### Summary of Changes

| # | What | File | Why |
|---|------|------|-----|
| 1 | Switch model from `gpt-image-1` to `flux-kontext` | `/app/api/photos/[id]/enhance/route.ts` | **Fixes 524 timeout.** flux-kontext does image editing in ~4-12 sec vs 100+ sec |
| 2 | Removed `quality: 'high'` from image_config | Same file | flux-kontext doesn't use this parameter; simplifies request |
| 3 | Added S3 re-upload of enhanced image | Same file | **Fixes CORS issue.** Downloads enhanced image server-side, re-uploads to your own S3 bucket |
| 4 | Added `uploadBufferToS3` helper | `/lib/s3.ts` | New helper function to upload a buffer directly to S3 |
| 5 | `maxDuration` reduced from 120 to 60 | Same file | flux-kontext is fast enough; 60s is plenty of headroom |

### Fallback Plan

If `flux-kontext` doesn't work or the image quality isn't good enough for real estate photos, try these models in order:
1. `flux-2-pro` — high-quality photorealistic generation, should still be faster than gpt-image-1
2. `dall-e` — DALL-E via Abacus, moderate speed
3. `gpt-image-1` with the async polling pattern (more complex, only do this as last resort)

The `[ENHANCE]` logging will show you exactly what happens. Check server logs after the first test.

Sources:
- [Abacus AI RouteLLM API Docs — supported image models](https://abacus.ai/help/developer-platform/route-llm/api)
- [FLUX.1 Kontext Dev API — 6x faster image editing](https://simplismart.ai/blog/flux-1-kontext-dev-api)
- [Runware — FLUX Kontext instruction-based editing](https://runware.ai/blog/introducing-flux1-kontext-instruction-based-image-editing-with-ai)
- [WaveSpeedAI — Flux Kontext benchmarks](https://wavespeed.ai/models/wavespeed-ai/flux-kontext-dev-ultra-fast)