Here is Claude Cohn's response :


Issue 1: HEIC Photo Previews Broken During Upload
Root Cause
The HEIC conversion code in photo-uploader.tsx looks structurally correct — heic2any is imported dynamically, the blob URL is created from the converted result, etc. The most likely cause is one of these:

The heic2any library may not be installed. If it's missing from package.json, the dynamic import('heic2any') will silently fail and hit the catch block, which falls back to URL.createObjectURL(file) on the raw HEIC file. Browsers (except Safari) cannot display HEIC files, so that fallback produces a broken preview.

The fallback in the catch block masks the real error. In photo-uploader.tsx:63-67, when conversion fails, it returns the original HEIC file as a blob URL. This will always show a broken image on Chrome/Firefox because those browsers don't support HEIC natively.

Fix for DeepAgent
Step A: Confirm heic2any is in package.json. If not, install it:

npm install heic2any

Step B: Change the error fallback in convertHeicToJpeg (around line 63-67 of photo-uploader.tsx). Instead of silently returning the unconverted file, show a proper error state:

} catch (error) {
  console.error('HEIC conversion failed:', error);
  // DON'T return the original HEIC file - browsers can't display it
  // Instead, return an empty preview so the fallback UI (filename icon) shows
  return { blob: file, preview: '' };
}

Step C: Also, the original HEIC File object is kept for upload (file on line 134), which means HEIC files are uploaded to S3 in HEIC format. Most browsers won't be able to display them in the admin dashboard either. The fix is to upload the converted JPEG blob instead of the original HEIC file. Change handleFiles around lines 121-140:

if (isHeicFile(file)) {
  const converted = await convertHeicToJpeg(file);
  preview = converted.preview;
  orientation = await checkOrientation(converted.blob);
  setConvertingCount(prev => Math.max(0, prev - 1));

  // Create a new File from the converted blob for upload
  const convertedFile = new File(
    [converted.blob],
    file.name.replace(/\.heic$/i, '.jpg').replace(/\.heif$/i, '.jpg'),
    { type: 'image/jpeg' }
  );

  newPhotos.push({
    id: `${Date.now()}-${i}`,
    file: convertedFile,  // Upload the converted JPEG, not the original HEIC
    preview,
    caption: '',
    subCategory: subcategories?.[0] || undefined,
    orientation,
    fileName: file.name
  });
} else {
  // ... existing code for non-HEIC files
}

This is important because even if previews work, the admin dashboard will still show broken images if raw HEIC files are sitting in S3.

Issue 2: Admin Dashboard Shows Broken Photos
Root Cause (this is the big one — likely multiple contributing factors)
Primary cause: The admin page uses the cloud_storage_path (an S3 key like uploads/123-photo.jpg) directly as an <img src>, not a full URL.

Look at admin/submissions/[id]/page.tsx:1730-1733:

<img
  src={photo.enhancedUrl || photo.originalUrl}
  alt={photo?.caption || 'Photo'}
  className="w-full h-full object-cover"
/>

photo.originalUrl contains the S3 key (e.g., public/uploads/1706123456-photo.jpg), not a full URL. The browser tries to load it as a relative path like https://yoursite.com/public/uploads/1706123456-photo.jpg, which doesn't exist on your web server — it's in S3.

The code does have a getS3Url helper function (lines 1440-1452) that calls /api/file-url to get a proper URL, but it's never actually used for the thumbnail images in the sidebar. It's only used in the main photo viewer area (line 1822), and even there, it does it inline with a fragile pattern.

Secondary cause: Content-Disposition header mismatch.

In lib/s3.ts:982, the presigned URL is generated with ContentDisposition: "attachment" for public files. This means S3 signs the URL expecting a Content-Disposition: attachment header. But the client-side upload code in submission-form.tsx:446-454 tries to detect this by checking if the URL string contains content-disposition:

const hasContentDisposition = uploadUrl?.includes?.('content-disposition');

This is fragile. The presigned URL query parameters are URL-encoded, so the string might be Content-Disposition or content-disposition or some encoded variant. If this check fails, the client won't send the Content-Disposition header, the upload will fail with a 403 SignatureDoesNotMatch error from S3, and the file never actually gets stored.

Third cause: Content-Disposition: attachment is wrong for images you want to display.

Even if the upload succeeds, Content-Disposition: attachment tells the browser to download the file rather than display it. For images you want to show in <img> tags, you should use inline or omit Content-Disposition entirely.

Fixes for DeepAgent
Fix A — Make the admin page resolve S3 URLs properly:

In admin/submissions/[id]/page.tsx, the thumbnail images and the main viewer both need to resolve the cloud_storage_path into real URLs. Add a state for resolved URLs and use the existing getS3Url function:

const [resolvedUrls, setResolvedUrls] = useState<Record<string, string>>({});

// After fetchSubmission succeeds, resolve all photo URLs
useEffect(() => {
  if (!submission?.photos) return;
  
  const resolveUrls = async () => {
    const urls: Record<string, string> = {};
    for (const photo of submission.photos) {
      if (photo.originalUrl && !photo.originalUrl.startsWith('http')) {
        urls[photo.originalUrl] = await getS3Url(photo.originalUrl);
      }
      if (photo.enhancedUrl && !photo.enhancedUrl.startsWith('http')) {
        urls[photo.enhancedUrl] = await getS3Url(photo.enhancedUrl);
      }
    }
    setResolvedUrls(urls);
  };
  
  resolveUrls();
}, [submission]);

Then use resolvedUrls[photo.originalUrl] || photo.originalUrl in all <img> tags.

Fix B — Remove or change Content-Disposition for public images:

In lib/s3.ts:978-983, change:

const command = new PutObjectCommand({
  Bucket: bucketName,
  Key: cloud_storage_path,
  ContentType: contentType,
  // Remove ContentDisposition entirely for images meant to be displayed
});

And remove the Content-Disposition logic from submission-form.tsx:446-454 as well — just delete the hasContentDisposition check and the related header.

Fix C — Fix the /api/file-url endpoint:

In app/api/file-url/route.ts:148, it always passes isPublic: true, which returns a plain S3 URL like https://bucket.s3.region.amazonaws.com/key. This will only work if the S3 bucket has public access enabled. If your bucket is private (which is typical), this URL will return 403 Forbidden. Change it to use a presigned GET URL instead:

// Change from:
const url = await getFileUrl(path, true);
// To:
const url = await getFileUrl(path, false);

This will generate a presigned URL that works regardless of bucket policy.

Summary to Give DeepAgent
Issue	Root Cause	Fix
HEIC previews broken	heic2any may not be installed; fallback returns unusable blob URL; original HEIC uploaded to S3	Install heic2any; fix error fallback; upload converted JPEG instead of raw HEIC
Admin photos broken	S3 key used directly as <img src> instead of resolved URL; Content-Disposition mismatch may cause upload to fail silently; bucket may not allow public access	Resolve S3 keys to presigned URLs before displaying; remove Content-Disposition: attachment; use presigned GET URLs in file-url endpoint
Additional Questions for You
Is heic2any listed in your package.json? This would immediately confirm/rule out the HEIC issue.
Is your S3 bucket configured for public access, or is it private? This determines whether the getFileUrl public URL approach can work at all.
Can you check the browser Network tab when the admin page loads — are the image requests returning 403, 404, or something else? That would pinpoint the exact failure.